{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import lxml\n",
    "import time\n",
    "import json\n",
    "from os import path\n",
    "import core_constants as cc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Rivals Team Commitments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = cc.get_defYears()\n",
    "headers= cc.get_header()\n",
    "conf = 'acc'\n",
    "\n",
    "schoolsList = cc.get_schoolsList()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cycle through each team and player to save the html file\n",
    "> Unlike 247Sports, this grabs both team and player pages in the same script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_recruits = []\n",
    "for y in years:\n",
    "    for school in schoolsList:\n",
    "        if (school['conference'][0] == conf):\n",
    "            url = 'https://{}.rivals.com/commitments/football/{}'.format(school['rivals'],y)\n",
    "            r = requests.get(url, headers=headers)\n",
    "            gameSoup = BeautifulSoup(r.text, 'lxml')\n",
    "            with open(\"..//html//rivals//\" + conf + \"//teams//\" + school['rivals'] + \"_\" + y + \".html\", \"w\") as write_file:\n",
    "                write_file.write(r.text)\n",
    "            print(school['rivals'] + \": \" + str(y))\n",
    "            print('------------------------------')\n",
    "            commitments = gameSoup.find(\"rv-commitments\")['prospects']\n",
    "            x = json.loads(commitments)\n",
    "\n",
    "            for commit in x:\n",
    "                if not (path.exists(\"..//html//rivals//\" + conf + \"//recruits//\" + str(commit['id']) + \"_\" + school['rivals'] + \"_\" + y + \".html\")):\n",
    "                    #go to player page\n",
    "                    recruitRequest = requests.get(commit['url'], headers=headers)\n",
    "                    recruitSoup = BeautifulSoup(recruitRequest.text, 'lxml')\n",
    "                    with open(\"..//html//rivals//\" + conf + \"//recruits//\" + str(commit['id']) + \"_\" + school['rivals'] + \"_\" + y + \".html\", \"w\") as write_file:\n",
    "                        write_file.write(recruitRequest.text)\n",
    "                    print(commit['id'])\n",
    "                    time.sleep(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
